{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:53:59.323328Z",
     "start_time": "2019-10-26T10:53:56.492314Z"
    }
   },
   "outputs": [],
   "source": [
    "from footbot.data import utils\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import PredefinedSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from footbot.optimiser import team_selector\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:54:04.494820Z",
     "start_time": "2019-10-26T10:54:04.484409Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:54:05.821508Z",
     "start_time": "2019-10-26T10:54:05.804693Z"
    }
   },
   "outputs": [],
   "source": [
    "client = utils.set_up_bigquery(secrets_path='../secrets/service_account.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:54:06.441078Z",
     "start_time": "2019-10-26T10:54:06.426448Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = \\\n",
    "'''\n",
    "SELECT\n",
    "  event,\n",
    "  fixture,\n",
    "  element,\n",
    "  total_points,\n",
    "  minutes,\n",
    "  safe_web_name,\n",
    "  element_type,\n",
    "  team,\n",
    "  value,\n",
    "  total_points_per_minute_previous_season,\n",
    "  goals_scored_per_minute_previous_season,\n",
    "  assists_per_minute_previous_season,\n",
    "  clean_sheets_per_minute_previous_season,\n",
    "  goals_conceded_per_minute_previous_season,\n",
    "  own_goals_per_minute_previous_season,\n",
    "  penalties_saved_per_minute_previous_season,\n",
    "  penalties_missed_per_minute_previous_season,\n",
    "  yellow_cards_per_minute_previous_season,\n",
    "  red_cards_per_minute_previous_season,\n",
    "  saves_per_minute_previous_season,\n",
    "  bonus_per_minute_previous_season,\n",
    "  bps_per_minute_previous_season,\n",
    "  opponent_team,\n",
    "  was_home,\n",
    "  was_sunday,\n",
    "  was_weekday,\n",
    "  was_late,\n",
    "  was_early,\n",
    "  rolling_avg_total_points_element,\n",
    "  rolling_avg_minutes_element,\n",
    "  rolling_avg_goals_scored_element,\n",
    "  rolling_avg_assists_element,\n",
    "  rolling_avg_clean_sheets_element,\n",
    "  rolling_avg_goals_conceded_element,\n",
    "  rolling_avg_own_goals_element,\n",
    "  rolling_avg_penalties_saved_element,\n",
    "  rolling_avg_penalties_missed_element,\n",
    "  rolling_avg_yellow_cards_element,\n",
    "  rolling_avg_red_cards_element,\n",
    "  rolling_avg_saves_element,\n",
    "  rolling_avg_bonus_element,\n",
    "  rolling_avg_bps_element,\n",
    "  rolling_avg_total_points_element_p1,\n",
    "  rolling_avg_total_points_element_p2,\n",
    "  rolling_avg_total_points_element_p3,\n",
    "  rolling_avg_total_points_element_p4,\n",
    "  rolling_avg_total_points_element_p5,\n",
    "  rolling_avg_total_points_element_p10,\n",
    "  rolling_avg_goals_scored_element_p1,\n",
    "  rolling_avg_goals_scored_element_p2,\n",
    "  rolling_avg_goals_scored_element_p3,\n",
    "  rolling_avg_goals_scored_element_p4,\n",
    "  rolling_avg_goals_scored_element_p5,\n",
    "  rolling_avg_goals_scored_element_p10,\n",
    "  rolling_avg_assists_element_p1,\n",
    "  rolling_avg_assists_element_p2,\n",
    "  rolling_avg_assists_element_p3,\n",
    "  rolling_avg_assists_element_p4,\n",
    "  rolling_avg_assists_element_p5,\n",
    "  rolling_avg_assists_element_p10,\n",
    "  rolling_avg_clean_sheets_element_p1,\n",
    "  rolling_avg_clean_sheets_element_p2,\n",
    "  rolling_avg_clean_sheets_element_p3,\n",
    "  rolling_avg_clean_sheets_element_p4,\n",
    "  rolling_avg_clean_sheets_element_p5,\n",
    "  rolling_avg_clean_sheets_element_p10,\n",
    "  rolling_avg_goals_conceded_element_p1,\n",
    "  rolling_avg_goals_conceded_element_p2,\n",
    "  rolling_avg_goals_conceded_element_p3,\n",
    "  rolling_avg_goals_conceded_element_p4,\n",
    "  rolling_avg_goals_conceded_element_p5,\n",
    "  rolling_avg_goals_conceded_element_p10,\n",
    "  rolling_avg_saves_element_p1,\n",
    "  rolling_avg_saves_element_p2,\n",
    "  rolling_avg_saves_element_p3,\n",
    "  rolling_avg_saves_element_p4,\n",
    "  rolling_avg_saves_element_p5,\n",
    "  rolling_avg_saves_element_p10,\n",
    "  rolling_avg_minutes_element_p1,\n",
    "  rolling_avg_minutes_element_p2,\n",
    "  rolling_avg_minutes_element_p3,\n",
    "  rolling_avg_minutes_element_p4,\n",
    "  rolling_avg_minutes_element_p5,\n",
    "  rolling_avg_minutes_element_p10,\n",
    "  rolling_avg_total_points_against_opponent_team_element_type,\n",
    "  rolling_avg_minutes_against_opponent_team_element_type,\n",
    "  rolling_avg_goals_scored_against_opponent_team_element_type,\n",
    "  rolling_avg_assists_against_opponent_team_element_type,\n",
    "  rolling_avg_clean_sheets_against_opponent_team_element_type,\n",
    "  rolling_avg_goals_conceded_against_opponent_team_element_type,\n",
    "  rolling_avg_own_goals_against_opponent_team_element_type,\n",
    "  rolling_avg_penalties_saved_against_opponent_team_element_type,\n",
    "  rolling_avg_penalties_missed_against_opponent_team_element_type,\n",
    "  rolling_avg_yellow_cards_against_opponent_team_element_type,\n",
    "  rolling_avg_red_cards_against_opponent_team_element_type,\n",
    "  rolling_avg_saves_against_opponent_team_element_type,\n",
    "  rolling_avg_bonus_against_opponent_team_element_type,\n",
    "  rolling_avg_bps_against_opponent_team_element_type,\n",
    "  rolling_avg_total_points_element_type,\n",
    "  rolling_avg_minutes_element_type,\n",
    "  rolling_avg_goals_scored_element_type,\n",
    "  rolling_avg_assists_element_type,\n",
    "  rolling_avg_clean_sheets_element_type,\n",
    "  rolling_avg_goals_conceded_element_type,\n",
    "  rolling_avg_own_goals_element_type,\n",
    "  rolling_avg_penalties_saved_element_type,\n",
    "  rolling_avg_penalties_missed_element_type,\n",
    "  rolling_avg_yellow_cards_element_type,\n",
    "  rolling_avg_red_cards_element_type,\n",
    "  rolling_avg_saves_element_type,\n",
    "  rolling_avg_bonus_element_type,\n",
    "  rolling_avg_bps_element_type,\n",
    "  expected_total_points_against_opponent_team_element_type,\n",
    "  expected_minutes_against_opponent_team_element_type,\n",
    "  expected_goals_scored_against_opponent_team_element_type,\n",
    "  expected_assists_against_opponent_team_element_type,\n",
    "  expected_clean_sheets_against_opponent_team_element_type,\n",
    "  expected_goals_conceded_against_opponent_team_element_type,\n",
    "  expected_own_goals_against_opponent_team_element_type,\n",
    "  expected_penalties_saved_against_opponent_team_element_type,\n",
    "  expected_penalties_missed_against_opponent_team_element_type,\n",
    "  expected_yellow_cards_against_opponent_team_element_type,\n",
    "  expected_red_cards_against_opponent_team_element_type,\n",
    "  expected_saves_against_opponent_team_element_type,\n",
    "  expected_bonus_against_opponent_team_element_type,\n",
    "  expected_bps_against_opponent_team_element_type,\n",
    "  rolling_avg_squad,\n",
    "  rolling_avg_first_team,\n",
    "  rolling_avg_vice_or_captain,\n",
    "  rolling_avg_squad_p1,\n",
    "  rolling_avg_first_team_p1,\n",
    "  rolling_avg_vice_or_captain_p1\n",
    "FROM\n",
    "  `footbot-001.fpl.element_gameweeks_features_1819_v01`\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:55:01.217665Z",
     "start_time": "2019-10-26T10:54:07.591097Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dataframe\n",
    "df_all = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:42.902951Z",
     "start_time": "2019-10-26T10:56:42.893813Z"
    }
   },
   "outputs": [],
   "source": [
    "last_train_event = 3\n",
    "last_test_event = 10\n",
    "element_filter_field = 'rolling_avg_total_points_element'\n",
    "element_filter_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:45.624464Z",
     "start_time": "2019-10-26T10:56:44.158264Z"
    }
   },
   "outputs": [],
   "source": [
    "# impute missing values by element type\n",
    "df = pd.concat([\n",
    "    df_all[df_all['element_type'] == i].fillna(\n",
    "        df_all[\n",
    "            (df_all['event'] <= last_train_event)\n",
    "            & (df_all['element_type'] == i)\n",
    "        ].mean()).fillna(0)\n",
    "    for i in range(1, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:48.655567Z",
     "start_time": "2019-10-26T10:56:48.650779Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df[df['element_type'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:49.093906Z",
     "start_time": "2019-10-26T10:56:49.082617Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all['predicted_total_points'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:51.679183Z",
     "start_time": "2019-10-26T10:56:51.656148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['value',\n",
       " 'total_points_per_minute_previous_season',\n",
       " 'goals_scored_per_minute_previous_season',\n",
       " 'assists_per_minute_previous_season',\n",
       " 'clean_sheets_per_minute_previous_season',\n",
       " 'goals_conceded_per_minute_previous_season',\n",
       " 'own_goals_per_minute_previous_season',\n",
       " 'penalties_saved_per_minute_previous_season',\n",
       " 'penalties_missed_per_minute_previous_season',\n",
       " 'yellow_cards_per_minute_previous_season',\n",
       " 'red_cards_per_minute_previous_season',\n",
       " 'saves_per_minute_previous_season',\n",
       " 'bonus_per_minute_previous_season',\n",
       " 'bps_per_minute_previous_season',\n",
       " 'rolling_avg_total_points_element',\n",
       " 'rolling_avg_minutes_element',\n",
       " 'rolling_avg_goals_scored_element',\n",
       " 'rolling_avg_assists_element',\n",
       " 'rolling_avg_clean_sheets_element',\n",
       " 'rolling_avg_goals_conceded_element',\n",
       " 'rolling_avg_own_goals_element',\n",
       " 'rolling_avg_penalties_saved_element',\n",
       " 'rolling_avg_penalties_missed_element',\n",
       " 'rolling_avg_yellow_cards_element',\n",
       " 'rolling_avg_red_cards_element',\n",
       " 'rolling_avg_saves_element',\n",
       " 'rolling_avg_bonus_element',\n",
       " 'rolling_avg_bps_element',\n",
       " 'rolling_avg_total_points_element_p1',\n",
       " 'rolling_avg_total_points_element_p2',\n",
       " 'rolling_avg_total_points_element_p3',\n",
       " 'rolling_avg_total_points_element_p4',\n",
       " 'rolling_avg_total_points_element_p5',\n",
       " 'rolling_avg_total_points_element_p10',\n",
       " 'rolling_avg_goals_scored_element_p1',\n",
       " 'rolling_avg_goals_scored_element_p2',\n",
       " 'rolling_avg_goals_scored_element_p3',\n",
       " 'rolling_avg_goals_scored_element_p4',\n",
       " 'rolling_avg_goals_scored_element_p5',\n",
       " 'rolling_avg_goals_scored_element_p10',\n",
       " 'rolling_avg_assists_element_p1',\n",
       " 'rolling_avg_assists_element_p2',\n",
       " 'rolling_avg_assists_element_p3',\n",
       " 'rolling_avg_assists_element_p4',\n",
       " 'rolling_avg_assists_element_p5',\n",
       " 'rolling_avg_assists_element_p10',\n",
       " 'rolling_avg_clean_sheets_element_p1',\n",
       " 'rolling_avg_clean_sheets_element_p2',\n",
       " 'rolling_avg_clean_sheets_element_p3',\n",
       " 'rolling_avg_clean_sheets_element_p4',\n",
       " 'rolling_avg_clean_sheets_element_p5',\n",
       " 'rolling_avg_clean_sheets_element_p10',\n",
       " 'rolling_avg_goals_conceded_element_p1',\n",
       " 'rolling_avg_goals_conceded_element_p2',\n",
       " 'rolling_avg_goals_conceded_element_p3',\n",
       " 'rolling_avg_goals_conceded_element_p4',\n",
       " 'rolling_avg_goals_conceded_element_p5',\n",
       " 'rolling_avg_goals_conceded_element_p10',\n",
       " 'rolling_avg_saves_element_p1',\n",
       " 'rolling_avg_saves_element_p2',\n",
       " 'rolling_avg_saves_element_p3',\n",
       " 'rolling_avg_saves_element_p4',\n",
       " 'rolling_avg_saves_element_p5',\n",
       " 'rolling_avg_saves_element_p10',\n",
       " 'rolling_avg_minutes_element_p1',\n",
       " 'rolling_avg_minutes_element_p2',\n",
       " 'rolling_avg_minutes_element_p3',\n",
       " 'rolling_avg_minutes_element_p4',\n",
       " 'rolling_avg_minutes_element_p5',\n",
       " 'rolling_avg_minutes_element_p10',\n",
       " 'rolling_avg_total_points_against_opponent_team_element_type',\n",
       " 'rolling_avg_minutes_against_opponent_team_element_type',\n",
       " 'rolling_avg_goals_scored_against_opponent_team_element_type',\n",
       " 'rolling_avg_assists_against_opponent_team_element_type',\n",
       " 'rolling_avg_clean_sheets_against_opponent_team_element_type',\n",
       " 'rolling_avg_goals_conceded_against_opponent_team_element_type',\n",
       " 'rolling_avg_own_goals_against_opponent_team_element_type',\n",
       " 'rolling_avg_penalties_saved_against_opponent_team_element_type',\n",
       " 'rolling_avg_penalties_missed_against_opponent_team_element_type',\n",
       " 'rolling_avg_yellow_cards_against_opponent_team_element_type',\n",
       " 'rolling_avg_red_cards_against_opponent_team_element_type',\n",
       " 'rolling_avg_saves_against_opponent_team_element_type',\n",
       " 'rolling_avg_bonus_against_opponent_team_element_type',\n",
       " 'rolling_avg_bps_against_opponent_team_element_type',\n",
       " 'rolling_avg_total_points_element_type',\n",
       " 'rolling_avg_minutes_element_type',\n",
       " 'rolling_avg_goals_scored_element_type',\n",
       " 'rolling_avg_assists_element_type',\n",
       " 'rolling_avg_clean_sheets_element_type',\n",
       " 'rolling_avg_goals_conceded_element_type',\n",
       " 'rolling_avg_own_goals_element_type',\n",
       " 'rolling_avg_penalties_saved_element_type',\n",
       " 'rolling_avg_penalties_missed_element_type',\n",
       " 'rolling_avg_yellow_cards_element_type',\n",
       " 'rolling_avg_red_cards_element_type',\n",
       " 'rolling_avg_saves_element_type',\n",
       " 'rolling_avg_bonus_element_type',\n",
       " 'rolling_avg_bps_element_type',\n",
       " 'expected_total_points_against_opponent_team_element_type',\n",
       " 'expected_minutes_against_opponent_team_element_type',\n",
       " 'expected_goals_scored_against_opponent_team_element_type',\n",
       " 'expected_assists_against_opponent_team_element_type',\n",
       " 'expected_clean_sheets_against_opponent_team_element_type',\n",
       " 'expected_goals_conceded_against_opponent_team_element_type',\n",
       " 'expected_own_goals_against_opponent_team_element_type',\n",
       " 'expected_penalties_saved_against_opponent_team_element_type',\n",
       " 'expected_penalties_missed_against_opponent_team_element_type',\n",
       " 'expected_yellow_cards_against_opponent_team_element_type',\n",
       " 'expected_red_cards_against_opponent_team_element_type',\n",
       " 'expected_saves_against_opponent_team_element_type',\n",
       " 'expected_bonus_against_opponent_team_element_type',\n",
       " 'expected_bps_against_opponent_team_element_type',\n",
       " 'rolling_avg_squad',\n",
       " 'rolling_avg_first_team',\n",
       " 'rolling_avg_vice_or_captain',\n",
       " 'rolling_avg_squad_p1',\n",
       " 'rolling_avg_first_team_p1',\n",
       " 'rolling_avg_vice_or_captain_p1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_feature_cols = [\n",
    "    i for i in df.columns if i not in [\n",
    "        'total_points',\n",
    "        'goals_scored',\n",
    "        'assists',\n",
    "        'clean_sheets',\n",
    "        'goals_conceded',\n",
    "        'saves',\n",
    "        'minutes',\n",
    "        'element',\n",
    "        'safe_web_name',\n",
    "        'element_type',\n",
    "        'cluster',\n",
    "        'team',\n",
    "        'event',\n",
    "        'fixture',\n",
    "        'opponent_team',\n",
    "        'was_home',\n",
    "        'was_sunday',\n",
    "        'was_weekday',\n",
    "        'was_late',\n",
    "        'was_early',\n",
    "    ]\n",
    "]\n",
    "\n",
    "scaled_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:52.387815Z",
     "start_time": "2019-10-26T10:56:52.378321Z"
    }
   },
   "outputs": [],
   "source": [
    "formula = \\\n",
    "'''\n",
    "total_points\n",
    "~ C(element_type)\n",
    "+ C(opponent_team)\n",
    "+ C(team)\n",
    "+ C(was_home)\n",
    "+ C(was_sunday)\n",
    "+ C(was_weekday)\n",
    "+ C(was_late)\n",
    "+ C(was_early)\n",
    "+\n",
    "'''  + ' + '.join(scaled_feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:53.453251Z",
     "start_time": "2019-10-26T10:56:53.363453Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_expected_dimension_against_opponent_team_element_type(\n",
    "    row,\n",
    "    feature\n",
    "):\n",
    "    dimension = feature[9:-35]\n",
    "    a = 'rolling_avg_' + dimension + '_against_opponent_team_element_type'\n",
    "    b = 'rolling_avg_' + dimension + '_element'\n",
    "    c = 'rolling_avg_' + dimension + '_element_type'\n",
    "    try:\n",
    "        return row[a] * row[b] / row[c]\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def munge_data(df, e, prediction_events, minute_threshold=60):\n",
    "    # filter weeks after test week\n",
    "    event_df = df.copy()\n",
    "    event_df = event_df[event_df['event'] <= e + prediction_events - 1]\n",
    "\n",
    "    cols = event_df.columns\n",
    "\n",
    "    # columns that we wouldn't know ahead of time, but can fill down\n",
    "    unknown_element_cols = [\n",
    "        'value',\n",
    "        'rolling_avg_total_points_element',\n",
    "        'rolling_avg_minutes_element',\n",
    "        'rolling_avg_goals_scored_element',\n",
    "        'rolling_avg_assists_element',\n",
    "        'rolling_avg_clean_sheets_element',\n",
    "        'rolling_avg_goals_conceded_element',\n",
    "        'rolling_avg_own_goals_element',\n",
    "        'rolling_avg_penalties_saved_element',\n",
    "        'rolling_avg_penalties_missed_element',\n",
    "        'rolling_avg_yellow_cards_element',\n",
    "        'rolling_avg_red_cards_element',\n",
    "        'rolling_avg_saves_element',\n",
    "        'rolling_avg_bonus_element',\n",
    "        'rolling_avg_bps_element',\n",
    "        'rolling_avg_total_points_element_p1',\n",
    "        'rolling_avg_total_points_element_p2',\n",
    "        'rolling_avg_total_points_element_p3',\n",
    "        'rolling_avg_total_points_element_p4',\n",
    "        'rolling_avg_total_points_element_p5',\n",
    "        'rolling_avg_total_points_element_p10',\n",
    "        'rolling_avg_goals_scored_element_p1',\n",
    "        'rolling_avg_goals_scored_element_p2',\n",
    "        'rolling_avg_goals_scored_element_p3',\n",
    "        'rolling_avg_goals_scored_element_p4',\n",
    "        'rolling_avg_goals_scored_element_p5',\n",
    "        'rolling_avg_goals_scored_element_p10',\n",
    "        'rolling_avg_assists_element_p1',\n",
    "        'rolling_avg_assists_element_p2',\n",
    "        'rolling_avg_assists_element_p3',\n",
    "        'rolling_avg_assists_element_p4',\n",
    "        'rolling_avg_assists_element_p5',\n",
    "        'rolling_avg_assists_element_p10',\n",
    "        'rolling_avg_clean_sheets_element_p1',\n",
    "        'rolling_avg_clean_sheets_element_p2',\n",
    "        'rolling_avg_clean_sheets_element_p3',\n",
    "        'rolling_avg_clean_sheets_element_p4',\n",
    "        'rolling_avg_clean_sheets_element_p5',\n",
    "        'rolling_avg_clean_sheets_element_p10',\n",
    "        'rolling_avg_goals_conceded_element_p1',\n",
    "        'rolling_avg_goals_conceded_element_p2',\n",
    "        'rolling_avg_goals_conceded_element_p3',\n",
    "        'rolling_avg_goals_conceded_element_p4',\n",
    "        'rolling_avg_goals_conceded_element_p5',\n",
    "        'rolling_avg_goals_conceded_element_p10',\n",
    "        'rolling_avg_saves_element_p1',\n",
    "        'rolling_avg_saves_element_p2',\n",
    "        'rolling_avg_saves_element_p3',\n",
    "        'rolling_avg_saves_element_p4',\n",
    "        'rolling_avg_saves_element_p5',\n",
    "        'rolling_avg_saves_element_p10',\n",
    "        'rolling_avg_minutes_element_p1',\n",
    "        'rolling_avg_minutes_element_p2',\n",
    "        'rolling_avg_minutes_element_p3',\n",
    "        'rolling_avg_minutes_element_p4',\n",
    "        'rolling_avg_minutes_element_p5',\n",
    "        'rolling_avg_minutes_element_p10',\n",
    "        'rolling_avg_total_points_element_type',\n",
    "        'rolling_avg_minutes_element_type',\n",
    "        'rolling_avg_goals_scored_element_type',\n",
    "        'rolling_avg_assists_element_type',\n",
    "        'rolling_avg_clean_sheets_element_type',\n",
    "        'rolling_avg_goals_conceded_element_type',\n",
    "        'rolling_avg_own_goals_element_type',\n",
    "        'rolling_avg_penalties_saved_element_type',\n",
    "        'rolling_avg_penalties_missed_element_type',\n",
    "        'rolling_avg_yellow_cards_element_type',\n",
    "        'rolling_avg_red_cards_element_type',\n",
    "        'rolling_avg_saves_element_type',\n",
    "        'rolling_avg_bonus_element_type',\n",
    "        'rolling_avg_bps_element_type',\n",
    "        'rolling_avg_squad',\n",
    "        'rolling_avg_first_team',\n",
    "        'rolling_avg_vice_or_captain',\n",
    "        'rolling_avg_squad_p1',\n",
    "        'rolling_avg_first_team_p1',\n",
    "        'rolling_avg_vice_or_captain_p1']\n",
    "\n",
    "    # columns that we wouldn't know ahead of time and need to look up\n",
    "    unknown_opponent_cols = [\n",
    "        'rolling_avg_total_points_against_opponent_team_element_type',\n",
    "        'rolling_avg_minutes_against_opponent_team_element_type',\n",
    "        'rolling_avg_goals_scored_against_opponent_team_element_type',\n",
    "        'rolling_avg_assists_against_opponent_team_element_type',\n",
    "        'rolling_avg_clean_sheets_against_opponent_team_element_type',\n",
    "        'rolling_avg_goals_conceded_against_opponent_team_element_type',\n",
    "        'rolling_avg_own_goals_against_opponent_team_element_type',\n",
    "        'rolling_avg_penalties_saved_against_opponent_team_element_type',\n",
    "        'rolling_avg_penalties_missed_against_opponent_team_element_type',\n",
    "        'rolling_avg_yellow_cards_against_opponent_team_element_type',\n",
    "        'rolling_avg_red_cards_against_opponent_team_element_type',\n",
    "        'rolling_avg_saves_against_opponent_team_element_type',\n",
    "        'rolling_avg_bonus_against_opponent_team_element_type',\n",
    "        'rolling_avg_bps_against_opponent_team_element_type',\n",
    "    ]\n",
    "\n",
    "    # columns that we wouldn't know ahead of time and we need to calculate\n",
    "    unknown_engineered_cols = [\n",
    "        'expected_total_points_against_opponent_team_element_type',\n",
    "        'expected_minutes_against_opponent_team_element_type',\n",
    "        'expected_goals_scored_against_opponent_team_element_type',\n",
    "        'expected_assists_against_opponent_team_element_type',\n",
    "        'expected_clean_sheets_against_opponent_team_element_type',\n",
    "        'expected_goals_conceded_against_opponent_team_element_type',\n",
    "        'expected_own_goals_against_opponent_team_element_type',\n",
    "        'expected_penalties_saved_against_opponent_team_element_type',\n",
    "        'expected_penalties_missed_against_opponent_team_element_type',\n",
    "        'expected_yellow_cards_against_opponent_team_element_type',\n",
    "        'expected_red_cards_against_opponent_team_element_type',\n",
    "        'expected_saves_against_opponent_team_element_type',\n",
    "        'expected_bonus_against_opponent_team_element_type',\n",
    "        'expected_bps_against_opponent_team_element_type',\n",
    "    ]\n",
    "\n",
    "    # fill in nans for future data we wouldn't know\n",
    "    event_df.loc[event_df['event'] > e,\n",
    "                 unknown_element_cols + unknown_opponent_cols + unknown_engineered_cols\n",
    "                ] = np.nan\n",
    "    event_df.sort_values(['element', 'event', 'fixture'], inplace=True)\n",
    "    \n",
    "    # fill down the element data\n",
    "    event_df[unknown_element_cols] = event_df[unknown_element_cols].fillna(method='ffill')\n",
    "\n",
    "    # create look up tables for opponent team data\n",
    "    # we have to look two events back, as some teams won't have played last event\n",
    "    against_opponent_event_df_1 = event_df[event_df['event'] == e][\n",
    "        ['opponent_team','element_type','event'] + unknown_opponent_cols].drop_duplicates()\n",
    "\n",
    "\n",
    "    against_opponent_event_df_2 = event_df[event_df['event'] == e - 1][\n",
    "        ['opponent_team','element_type','event'] + unknown_opponent_cols].drop_duplicates()\n",
    "\n",
    "    against_opponent_event_df = pd.concat([against_opponent_event_df_1, against_opponent_event_df_2])\n",
    "\n",
    "    # get the most recent opponent team data\n",
    "    against_opponent_event_df = against_opponent_event_df.join(\n",
    "        against_opponent_event_df.groupby(['opponent_team', 'element_type'])['event'].max(),\n",
    "        on=['opponent_team', 'element_type'],\n",
    "        rsuffix='_most_recent')\n",
    "\n",
    "    against_opponent_event_df = \\\n",
    "    against_opponent_event_df[against_opponent_event_df['event'] == against_opponent_event_df['event_most_recent']]\n",
    "\n",
    "    event_df = event_df.join(\n",
    "        against_opponent_event_df.set_index(['opponent_team', 'element_type']),\n",
    "        on=['opponent_team', 'element_type'],\n",
    "        rsuffix='_fill')\n",
    "\n",
    "    # fill in opponent team data from lookup table\n",
    "    for i in unknown_opponent_cols:\n",
    "        event_df.loc[event_df['event'] > e, i] = event_df[event_df['event'] > e][i+'_fill']\n",
    "\n",
    "    # calculate calculated fields\n",
    "    for i in unknown_engineered_cols:\n",
    "        event_df[i] = event_df.apply(\n",
    "            calculate_expected_dimension_against_opponent_team_element_type,\n",
    "            axis=1,\n",
    "            args=(i,)\n",
    "        )\n",
    "\n",
    "\n",
    "    # filter out irrelevant players\n",
    "    event_df = event_df[\n",
    "        event_df[element_filter_field] > element_filter_value\n",
    "    ][cols]\n",
    "    \n",
    "    return event_df\n",
    "\n",
    "\n",
    "def split_data(event_df, last_train_event, last_test_event):\n",
    "    # define train-test split\n",
    "    test_fold = [-1 if i <= last_train_event else 0 for i in event_df['event'] if i <= last_test_event]\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "    # split df into train and test\n",
    "    for train_index, test_index in ps.split():\n",
    "        event_df_train, event_df_test = \\\n",
    "        event_df.copy().iloc[train_index], event_df.copy().iloc[test_index]\n",
    "    \n",
    "    return event_df_train, event_df_test, ps\n",
    "\n",
    "\n",
    "def standardise_data(event_df, event_df_train, event_df_test, scaled_feature_cols):\n",
    "    scale_train = event_df_train.copy()\n",
    "    scale_test = event_df_test.copy()\n",
    "    scale_df = event_df.copy()\n",
    "    scaled_event_df_train = event_df_train.copy()\n",
    "    scaled_event_df_test = event_df_test.copy()\n",
    "    scaled_event_df = event_df.copy()\n",
    "\n",
    "    scaler = StandardScaler().fit(scale_train[scaled_feature_cols].values)\n",
    "\n",
    "    scale_train = scaler.transform(scale_train[scaled_feature_cols].values)\n",
    "    scale_test = scaler.transform(scale_test[scaled_feature_cols].values)\n",
    "    scale_df = scaler.transform(scale_df[scaled_feature_cols].values)\n",
    "\n",
    "    scaled_event_df_train[scaled_feature_cols] = scale_train\n",
    "    scaled_event_df_test[scaled_feature_cols] = scale_test\n",
    "    scaled_event_df[scaled_feature_cols] = scale_df\n",
    "    \n",
    "    return scaled_event_df_train, scaled_event_df_test, scaled_event_df\n",
    "\n",
    "\n",
    "def get_pcs(event_X_train, event_X_test, n_categorical_features):\n",
    "    pca = PCA()\n",
    "    pca.fit(event_X_train[:,(n_categorical_features + 1):])\n",
    "    \n",
    "    event_X_train_pca = np.concatenate(\n",
    "        (\n",
    "            event_X_train[:,:(n_categorical_features + 1)],\n",
    "            pca.transform(event_X_train[:,(n_categorical_features + 1):])\n",
    "        ), axis=1)\n",
    "    \n",
    "    event_X_test_pca = np.concatenate(\n",
    "        (\n",
    "            event_X_test[:,:(n_categorical_features + 1)],\n",
    "            pca.transform(event_X_test[:,(n_categorical_features + 1):])\n",
    "        ), axis=1)\n",
    "    \n",
    "    return event_X_train_pca, event_X_test_pca\n",
    "\n",
    "\n",
    "def split_matrices(event_X, event_y, ps):\n",
    "    for train_index, test_index in ps.split():\n",
    "        event_X_train, event_X_test = event_X[train_index], event_X[test_index]\n",
    "        event_y_train, event_y_test = event_y[train_index], event_y[test_index]\n",
    "    \n",
    "    return event_X_train, event_X_test, event_y_train, event_y_test\n",
    "\n",
    "\n",
    "def select_features(event_X, event_X_train, event_X_test, features_index):    \n",
    "    event_X_train_sel = event_X_train[:,features_index]\n",
    "    event_X_test_sel = event_X_test[:,features_index]\n",
    "    event_X_sel = event_X[:,features_index]\n",
    "    \n",
    "    return event_X_train_sel, event_X_test_sel, event_X_sel\n",
    "\n",
    "\n",
    "def retune_model(event_df,\n",
    "                 last_train_event,\n",
    "                 last_validation_event,\n",
    "                 standardise,\n",
    "                 features_index,\n",
    "                 model,\n",
    "                 parameter_space,\n",
    "                 n_iter_tune=100):\n",
    "    \n",
    "    # split data into train and validation set\n",
    "    event_df_train, event_df_validation, ps_tune = split_data(event_df, last_train_event, last_validation_event)\n",
    "\n",
    "    # standardise appropriate variables if necessary\n",
    "    scaled_event_df = event_df.copy()\n",
    "    if standardise:\n",
    "        scaled_event_df_train, scaled_event_df_validation, scaled_event_df = \\\n",
    "        standardise_data(event_df, event_df_train, event_df_validation, scaled_feature_cols)        \n",
    "\n",
    "    # get reponse vector and feature matrix\n",
    "    event_y, event_X = patsy.dmatrices(formula, scaled_event_df, return_type='matrix')\n",
    "\n",
    "    # split response vector and feature matrix into train and test\n",
    "    event_X_train, event_X_validation, event_y_train, event_y_validation = \\\n",
    "    split_matrices(event_X, event_y, ps_tune)\n",
    "\n",
    "    # if only certain features selected, get their indices\n",
    "    event_X_train_sel = event_X_train\n",
    "    event_X_validation_sel = event_X_validation\n",
    "    event_X_sel = event_X\n",
    "    if features_index:\n",
    "        event_X_train_sel, event_X_validation_sel, event_X_sel = \\\n",
    "        select_features(event_X, event_X_train, event_X_validation, features_index)\n",
    "    \n",
    "    # search hyperparameter space\n",
    "    tuner = RandomizedSearchCV(\n",
    "        model,\n",
    "        parameter_space,\n",
    "        n_iter=n_iter_tune,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        refit=True,\n",
    "        cv=ps_tune,\n",
    "        error_score=100, n_jobs=1)\n",
    "    \n",
    "    tuner.fit(event_X_sel, event_y.ravel())\n",
    "    \n",
    "    return tuner.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:56:54.097410Z",
     "start_time": "2019-10-26T10:56:54.046654Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_team_total_points(df,\n",
    "                                first_team_elements,\n",
    "                                captain_elements,\n",
    "                                bench_elements,\n",
    "                                event,\n",
    "                                num_transfers=0,\n",
    "                                carried_over_transfers=0\n",
    "                               ):\n",
    "    df = df.copy()\n",
    "    df = df[df['event'] == event]\n",
    "    df = df[df['element'].isin(list(first_team_elements) + list(bench_elements))]\n",
    "    df['is_first_team'] = 0\n",
    "    df.loc[df['element'].isin(list(first_team_elements)),'is_first_team'] = 1\n",
    "    df['is_captain'] = 0\n",
    "    df.loc[df['element'].isin(list(captain_elements)),'is_captain'] = 1\n",
    "\n",
    "\n",
    "    df_group = df.groupby('element')[['predicted_total_points', 'total_points', 'minutes']].sum()\n",
    "    df = df[['safe_web_name', 'element', 'value', 'element_type', 'is_first_team', 'is_captain']].drop_duplicates()\n",
    "    df = df.join(df_group, on='element')\n",
    "    df.sort_values('predicted_total_points', ascending=False, inplace=True)\n",
    "\n",
    "    captain_selection = captain_elements[0]\n",
    "    vice_selection = df.iloc[1]['element']\n",
    "\n",
    "    is_captain_missing = len(df[(df['element'] == captain_selection) & (df['minutes'] == 0)])\n",
    "\n",
    "    if is_captain_missing:\n",
    "        df['is_captain'] = df['element'].apply(lambda x: 1 if x == vice_selection else 0)\n",
    "    else:\n",
    "        df['is_captain'] = df['element'].apply(lambda x: 1 if x == captain_selection else 0)\n",
    "\n",
    "    missing_players = list(df[(df['minutes'] == 0) & (df['is_first_team'] == 1)]['element'])\n",
    "    present_bench_players = list(df[(df['minutes'] > 0) & (df['is_first_team'] == 0)]['element'])\n",
    "    num_missing_players = len(missing_players)\n",
    "    num_present_bench_players = len(present_bench_players)\n",
    "\n",
    "    if num_missing_players > 0:\n",
    "\n",
    "        num_keepers = 1\n",
    "        min_defenders = 3\n",
    "        min_midfielders = 2\n",
    "        min_strikers = 1\n",
    "\n",
    "        df[df['minutes'] == 0]\n",
    "\n",
    "        for i in range(0, min(3, num_missing_players, num_present_bench_players)):\n",
    "            substitute = df[df['is_first_team'] == 0].iloc[i]['element']\n",
    "\n",
    "            for missing_player in missing_players:\n",
    "                sub_loop_df = df.copy()\n",
    "\n",
    "                sub_loop_df.loc[sub_loop_df['element'] == substitute,'is_first_team'] = 1\n",
    "                sub_loop_df.loc[sub_loop_df['element'] == missing_player,'is_first_team'] = 0\n",
    "\n",
    "                num_team_keepers = len(\n",
    "                    sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 1)])\n",
    "                num_team_defenders = len(\n",
    "                    sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 2)])\n",
    "                num_team_midfielders = len(\n",
    "                    sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 3)])\n",
    "                num_team_strikers = len(\n",
    "                    sub_loop_df[(sub_loop_df['is_first_team'] == 1) & (sub_loop_df['element_type'] == 4)])\n",
    "\n",
    "                if (\n",
    "                    (num_team_keepers == num_keepers)\n",
    "                    & (num_team_defenders >= min_defenders)\n",
    "                    & (num_team_midfielders >= min_midfielders)\n",
    "                    & (num_team_strikers >= min_strikers)\n",
    "                ):\n",
    "                    df = sub_loop_df.copy()\n",
    "                    missing_players = list(df[(df['minutes'] == 0) & (df['is_first_team'] == 1)]['element'])\n",
    "                    num_missing_players = len(missing_players)\n",
    "                    break\n",
    "\n",
    "\n",
    "    transfer_cost = max(num_transfers - carried_over_transfers - 1, 0) * 4\n",
    "\n",
    "    team_total_points = \\\n",
    "    sum(df[df['is_first_team'] == 1]['total_points'] * (df[df['is_first_team'] == 1]['is_captain'] + 1))\n",
    "\n",
    "    team_predicted_total_points = \\\n",
    "    sum(df[df['is_first_team'] == 1]['predicted_total_points'] * (df[df['is_first_team'] == 1]['is_captain'] + 1))\n",
    "\n",
    "    return team_total_points - transfer_cost, team_predicted_total_points, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:58:35.829845Z",
     "start_time": "2019-10-26T10:58:35.798248Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_test_set(df,\n",
    "                     model,\n",
    "                     parameter_space=False,\n",
    "                     prediction_events=1,\n",
    "                     prediction_weight=1,\n",
    "                     features_index=False,\n",
    "                     standardise=False,\n",
    "                     pcs=False,\n",
    "                     start=21,\n",
    "                     end=38,\n",
    "                     n_iter_tune=100,\n",
    "                     verbose=0):\n",
    "    y_pred_arr = []\n",
    "    y_test_arr = []\n",
    "    event_df_test_arr = []\n",
    "\n",
    "    # for each event we want to predict\n",
    "    for e in range(start, end + 1):\n",
    "        if verbose > 0:\n",
    "            print('predicting event', e)\n",
    "        \n",
    "        # munge data\n",
    "        event_df = munge_data(df, e, prediction_events)\n",
    "\n",
    "        # split df into train and test\n",
    "        event_df_train, event_df_test, ps = split_data(event_df, e - 1, 38)\n",
    "        \n",
    "        # standardise appropriate variables if necessary\n",
    "        scaled_event_df = event_df.copy()\n",
    "        if standardise:\n",
    "            scaled_event_df_train, scaled_event_df_test, scaled_event_df = \\\n",
    "            standardise_data(event_df, event_df_train, event_df_test, scaled_feature_cols)\n",
    "\n",
    "        # get reponse vector and feature matrix\n",
    "        event_y, event_X = patsy.dmatrices(formula, scaled_event_df, return_type='matrix')\n",
    "        \n",
    "        # split response vector and feature matrix into train and test\n",
    "        event_X_train, event_X_test, event_y_train, event_y_test = \\\n",
    "        split_matrices(event_X, event_y, ps)\n",
    "        \n",
    "        # get pcs if necessary\n",
    "        if pcs:\n",
    "            n_categorical_features = event_X.design_info.column_names.index('value') - 1\n",
    "            event_X_train, event_X_test = get_pcs(event_X_train, event_X_test, n_categorical_features)\n",
    "        \n",
    "        # if only certain features selected, get their indices\n",
    "        event_X_train_sel = event_X_train\n",
    "        event_X_test_sel = event_X_test\n",
    "        event_X_sel = event_X\n",
    "        if features_index:\n",
    "            event_X_train_sel, event_X_test_sel, event_X_sel = \\\n",
    "            select_features(event_X, event_X_train, event_X_test, features_index)\n",
    "            \n",
    "        # retune hyperparameters\n",
    "        if parameter_space:\n",
    "            model = retune_model(event_df,\n",
    "                                 e - 6,\n",
    "                                 e - 1,\n",
    "                                 standardise,\n",
    "                                 features_index,\n",
    "                                 model,\n",
    "                                 parameter_space,\n",
    "                                 n_iter_tune)\n",
    "\n",
    "        # fit model on training data\n",
    "        model.fit(event_X_train_sel, event_y_train.ravel())\n",
    "        # predict test event\n",
    "        event_y_pred = model.predict(event_X_test_sel).flatten()\n",
    "        \n",
    "        # collect predictions and observations \n",
    "        y_pred_arr.append(event_y_pred)\n",
    "        y_test_arr.append(event_y_test)\n",
    "        \n",
    "        event_df_test['predicted_total_points'] = event_y_pred\n",
    "        event_df_test['prediction_event'] = e\n",
    "        \n",
    "        event_df_test_arr.append(event_df_test)\n",
    "        \n",
    "    return np.concatenate(y_pred_arr).ravel(), np.concatenate(y_test_arr).ravel(), pd.concat(event_df_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:58:38.218765Z",
     "start_time": "2019-10-26T10:58:38.197227Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_event_players(\n",
    "    df,\n",
    "    e,\n",
    "    prediction_events,\n",
    "    optimise_key,\n",
    "    prediction_weight):\n",
    "    \n",
    "    event_players = df.copy()\n",
    "    \n",
    "    event_players = \\\n",
    "    event_players[\n",
    "        (event_players['prediction_event'] == e)\n",
    "        & (event_players['event'] <= e + prediction_events - 1)\n",
    "    ]        \n",
    "    present_elements = event_players['element'].drop_duplicates().values\n",
    "    df_all_players = df_all.copy()\n",
    "    df_all_players = df_all_players[df_all_players['event'] == e]\n",
    "    df_all_players['prediction_event'] = e\n",
    "    event_players = pd.concat([event_players, df_all_players[~df_all_players['element'].isin(present_elements)]])\n",
    "    \n",
    "    \n",
    "    event_players['event_diff'] = event_players['event'] - event_players['prediction_event']\n",
    "    event_players['prediction_weight'] = prediction_weight**(event_players['event_diff'])\n",
    "    event_players['optimise_key_weighted'] = event_players['prediction_weight'] * event_players[optimise_key]\n",
    "    \n",
    "    event_players_df = event_players.copy()\n",
    "    \n",
    "    event_players_group = event_players.groupby('element')['optimise_key_weighted'].sum()\n",
    "    event_players = event_players[['element', 'value', 'element_type', 'team']].drop_duplicates()\n",
    "    event_players = event_players.join(event_players_group, on='element')\n",
    "    event_players = event_players.to_dict('records')\n",
    "    \n",
    "    return event_players, event_players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:58:39.128695Z",
     "start_time": "2019-10-26T10:58:39.085140Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_event_teams(df,\n",
    "                          prediction_events=1,\n",
    "                          prediction_weight=1,\n",
    "                          from_scratch_prediction_events=1,\n",
    "                          optimise_key='predicted_total_points',\n",
    "                          start=21,\n",
    "                          end=38,\n",
    "                          total_budget=1000,\n",
    "                          captain_factor=2,\n",
    "                          bench_factor=0.1,\n",
    "                          transfer_penalty=4,\n",
    "                          transfer_limit=15,\n",
    "                          verbose=0\n",
    "                         ):\n",
    "    first_team_arr = []\n",
    "    captain_arr = []\n",
    "    bench_arr = []\n",
    "    transfers_arr = []\n",
    "    team_total_points_arr = []\n",
    "    predicted_team_total_points_arr = []\n",
    "    team_df_arr = []\n",
    "    carried_over_transfers = 0\n",
    "    \n",
    "    for e in range(start, end + 1):\n",
    "        if verbose > 0:\n",
    "            print('selecting team for event', e)\n",
    "        \n",
    "        event_players, event_players_df = get_event_players(\n",
    "            df,\n",
    "            e,\n",
    "            prediction_events,\n",
    "            optimise_key,\n",
    "            prediction_weight\n",
    "        )\n",
    "        \n",
    "        from_scratch_event_players, _ = get_event_players(\n",
    "            df,\n",
    "            e,\n",
    "            from_scratch_prediction_events,\n",
    "            optimise_key,\n",
    "            prediction_weight\n",
    "        )\n",
    "        \n",
    "        if e == start:\n",
    "            try:\n",
    "                event_first_team, event_captain, event_bench, event_transfers = \\\n",
    "                team_selector.select_team(\n",
    "                    from_scratch_event_players,\n",
    "                    optimise_key='optimise_key_weighted',\n",
    "                    total_budget=total_budget,\n",
    "                    captain_factor=captain_factor,\n",
    "                    bench_factor=bench_factor,\n",
    "                    existing_squad_elements=None,\n",
    "                    transfer_penalty=transfer_penalty,\n",
    "                    transfer_limit=transfer_limit\n",
    "                )\n",
    "\n",
    "                first_team_arr.append(event_first_team)\n",
    "                captain_arr.append(event_captain)\n",
    "                bench_arr.append(event_bench)\n",
    "                transfers_arr.append(event_transfers)\n",
    "                \n",
    "                event_num_transfers = 1\n",
    "            except Exception as ex:\n",
    "                print(e, ex)\n",
    "                first_team_arr.append([])\n",
    "                captain_arr.append([])\n",
    "                bench_arr.append([])\n",
    "                transfers_arr.append([])\n",
    "                \n",
    "                event_num_transfers = 1\n",
    "        else:\n",
    "            try:\n",
    "                existing_squad_elements = event_first_team + event_bench\n",
    "                \n",
    "                event_first_team, event_captain, event_bench, event_transfers = \\\n",
    "                team_selector.select_team(\n",
    "                    event_players,\n",
    "                    optimise_key='optimise_key_weighted',\n",
    "                    total_budget=total_budget,\n",
    "                    captain_factor=captain_factor,\n",
    "                    bench_factor=bench_factor,\n",
    "                    existing_squad_elements=existing_squad_elements,\n",
    "                    transfer_penalty=transfer_penalty,\n",
    "                    transfer_limit=transfer_limit\n",
    "                )\n",
    "\n",
    "                first_team_arr.append(event_first_team)\n",
    "                captain_arr.append(event_captain)\n",
    "                bench_arr.append(event_bench)\n",
    "                transfers_arr.append(event_transfers)\n",
    "                \n",
    "                event_num_transfers = len(event_transfers['transfers_in'])\n",
    "            except Exception as ex:\n",
    "                print(e, ex)\n",
    "                first_team_arr.append(event_first_team)\n",
    "                captain_arr.append(event_captain)\n",
    "                bench_arr.append(event_bench)\n",
    "                transfers_arr.append({\n",
    "                    'transfers_in': set(),\n",
    "                    'transfers_out': set()})\n",
    "                \n",
    "                event_num_transfers = 0\n",
    "        \n",
    "        event_num_transfers = max(event_num_transfers - carried_over_transfers, 0)\n",
    "        \n",
    "        event_team_total_points, event_team_predicted_total_points, event_team_df = \\\n",
    "        calculate_team_total_points(event_players_df,\n",
    "                                    event_first_team,\n",
    "                                    event_captain,\n",
    "                                    event_bench,\n",
    "                                    e,\n",
    "                                    event_num_transfers,\n",
    "                                    carried_over_transfers)\n",
    "        \n",
    "        if event_num_transfers == 0 and carried_over_transfers == 0:\n",
    "            carried_over_transfers = 1\n",
    "        if event_num_transfers in (0, 1) and carried_over_transfers == 1:\n",
    "            carried_over_transfers = 1\n",
    "        if event_num_transfers == 1 and carried_over_transfers == 0:\n",
    "            carried_over_transfers = 0\n",
    "        if event_num_transfers > 1:\n",
    "            carried_over_transfers = 0\n",
    "\n",
    "\n",
    "        team_total_points_arr.append(event_team_total_points)\n",
    "        predicted_team_total_points_arr.append(event_team_predicted_total_points)\n",
    "        team_df_arr.append(event_team_df)\n",
    "    \n",
    "    return (\n",
    "        first_team_arr, bench_arr,\n",
    "        team_total_points_arr,\n",
    "        predicted_team_total_points_arr,\n",
    "        team_df_arr,\n",
    "        transfers_arr\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T10:58:43.408368Z",
     "start_time": "2019-10-26T10:58:43.399323Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-26T10:59:10.308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting event 21\n",
      "predicting event 22\n",
      "predicting event 23\n"
     ]
    }
   ],
   "source": [
    "ls_y_pred, ls_y_test, ls_df_test = predict_test_set(\n",
    "    df,\n",
    "    ls_model,\n",
    "    standardise=True,\n",
    "    pcs=False,\n",
    "    prediction_events=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-26T10:59:40.070Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_test_loss = (\n",
    "    mean_absolute_error(ls_y_test, ls_y_pred),\n",
    "    mean_squared_error(ls_y_test, ls_y_pred),\n",
    "    r2_score(ls_y_test, ls_y_pred)\n",
    ")\n",
    "ls_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:43:30.320843Z",
     "start_time": "2019-10-20T11:43:23.762020Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ls_first_team_arr,\n",
    "    ls_bench_arr,\n",
    "    ls_total_points_arr,\n",
    "    ls_predicted_total_points_arr,\n",
    "    ls_team_df_arr,\n",
    "    ls_transfers_arr\n",
    ") = \\\n",
    "construct_event_teams(\n",
    "    ls_df_test,\n",
    "    total_budget=1000,\n",
    "    prediction_events=2,\n",
    "    from_scratch_prediction_events=5,\n",
    "    transfer_penalty=4,\n",
    "    transfer_limit=1,\n",
    "    verbose=1)\n",
    "    \n",
    "\n",
    "ls_total_points = sum(ls_total_points_arr)\n",
    "ls_total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:50:09.964739Z",
     "start_time": "2019-10-20T11:50:09.960576Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:56:56.169362Z",
     "start_time": "2019-10-20T11:50:09.968746Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_y_pred, ridge_y_test, ridge_df_test = predict_test_set(\n",
    "    df,\n",
    "    ridge_model,\n",
    "    standardise=True,\n",
    "    pcs=False,\n",
    "    prediction_events=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:56:56.179035Z",
     "start_time": "2019-10-20T11:56:56.171695Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_test_loss = (\n",
    "    mean_absolute_error(ridge_y_test, ridge_y_pred),\n",
    "    mean_squared_error(ridge_y_test, ridge_y_pred),\n",
    "    r2_score(ridge_y_test, ridge_y_pred)\n",
    ")\n",
    "ridge_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T12:32:50.992313Z",
     "start_time": "2019-10-20T12:32:41.767856Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ridge_first_team_arr,\n",
    "    ridge_bench_arr,\n",
    "    ridge_total_points_arr,\n",
    "    ridge_predicted_total_points_arr,\n",
    "    ridge_team_df_arr,\n",
    "    ridge_transfers_arr\n",
    ") = \\\n",
    "construct_event_teams(\n",
    "    ridge_df_test,\n",
    "    total_budget=1057.75,\n",
    "    prediction_events=2,\n",
    "    from_scratch_prediction_events=5,\n",
    "    transfer_penalty=4,\n",
    "    transfer_limit=1,\n",
    "    verbose=1)\n",
    "    \n",
    "\n",
    "ridge_total_points = sum(ridge_total_points_arr)\n",
    "ridge_total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:50:09.964739Z",
     "start_time": "2019-10-20T11:50:09.960576Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:56:56.169362Z",
     "start_time": "2019-10-20T11:50:09.968746Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_y_pred, lasso_y_test, lasso_df_test = predict_test_set(\n",
    "    df,\n",
    "    lasso_model,\n",
    "    standardise=True,\n",
    "    pcs=False,\n",
    "    prediction_events=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T11:56:56.179035Z",
     "start_time": "2019-10-20T11:56:56.171695Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_test_loss = (\n",
    "    mean_absolute_error(lasso_y_test, lasso_y_pred),\n",
    "    mean_squared_error(lasso_y_test, lasso_y_pred),\n",
    "    r2_score(lasso_y_test, lasso_y_pred)\n",
    ")\n",
    "lasso_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T12:32:50.992313Z",
     "start_time": "2019-10-20T12:32:41.767856Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lasso_first_team_arr,\n",
    "    lasso_bench_arr,\n",
    "    lasso_total_points_arr,\n",
    "    lasso_predicted_total_points_arr,\n",
    "    lasso_team_df_arr,\n",
    "    lasso_transfers_arr\n",
    ") = \\\n",
    "construct_event_teams(\n",
    "    lasso_df_test,\n",
    "    total_budget=1040,\n",
    "    prediction_events=2,\n",
    "    prediction_weight=1,\n",
    "    from_scratch_prediction_events=5,\n",
    "    transfer_penalty=4,\n",
    "    transfer_limit=2,\n",
    "    bench_factor=0.1,\n",
    "    verbose=1)\n",
    "    \n",
    "\n",
    "lasso_total_points = sum(lasso_total_points_arr)\n",
    "lasso_total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T07:44:36.873236Z",
     "start_time": "2019-10-20T07:44:29.667Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boost_teams_total_points_arr = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    print('iteration ', i)\n",
    "    boost_model = GradientBoostingRegressor(\n",
    "        criterion='mse',\n",
    "        min_samples_leaf=0.0175,\n",
    "        max_features=1.0,\n",
    "        learning_rate=0.02,\n",
    "        subsample=0.3,\n",
    "        n_estimators=200\n",
    "    )\n",
    "    \n",
    "    boost_y_pred, boost_y_test, boost_df_test = predict_test_set(\n",
    "    df,\n",
    "    boost_model,\n",
    "    standardise=False,\n",
    "    prediction_events=5,\n",
    "    verbose=0)\n",
    "    \n",
    "    (\n",
    "        boost_first_team_arr,\n",
    "        boost_bench_arr,\n",
    "        boost_total_points_arr,\n",
    "        boost_predicted_total_points_arr,\n",
    "        boost_team_df_arr,\n",
    "        boost_transfers_arr\n",
    "    ) = \\\n",
    "    construct_event_teams_from_existing(\n",
    "        boost_df_test,\n",
    "        total_budget=1057.5,\n",
    "        prediction_events=2,\n",
    "        from_scratch_prediction_events=5,\n",
    "        transfer_penalty=4,\n",
    "        transfer_limit=1,\n",
    "        verbose=0)\n",
    "    \n",
    "    boost_teams_total_points = sum(boost_total_points_arr)\n",
    "    boost_teams_total_points_arr.append(boost_teams_total_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:21:17.906128Z",
     "start_time": "2019-08-25T08:21:17.895644Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "boost_teams_total_points_mean = np.mean(boost_teams_total_points_arr) \n",
    "boost_teams_total_points_std = np.std(boost_teams_total_points_arr)\n",
    "    \n",
    "boost_teams_total_points_mean, boost_teams_total_points_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random team benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:02:44.543920Z",
     "start_time": "2019-08-16T12:02:44.538518Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_benchmark_df_test = lr_df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T22:02:31.851263Z",
     "start_time": "2019-08-24T21:06:34.897034Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_benchmark_teams_total_points_arr = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    random_benchmark_df_test['predicted_total_points'] = \\\n",
    "    np.random.random(len(lr_df_test['predicted_total_points'])) * 7\n",
    "    \n",
    "    (\n",
    "        random_benchmark_first_team_arr,\n",
    "        random_benchmark_bench_arr,\n",
    "        random_benchmark_total_points_arr,\n",
    "        random_benchmark_predicted_total_points_arr,\n",
    "        random_benchmark_team_df_arr,\n",
    "        random_benchmark_transfers_arr\n",
    "    ) = \\\n",
    "    construct_event_teams_from_existing(\n",
    "        random_benchmark_df_test,\n",
    "        total_budget=1057.5,\n",
    "        prediction_events=2,\n",
    "        from_scratch_prediction_events=5,\n",
    "        transfer_penalty=4,\n",
    "        transfer_limit=1,\n",
    "        verbose=1)\n",
    "    \n",
    "    random_benchmark_teams_total_points = sum(random_benchmark_total_points_arr)\n",
    "    random_benchmark_teams_total_points_arr.append(random_benchmark_teams_total_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:21:36.107741Z",
     "start_time": "2019-08-25T08:21:36.098173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_benchmark_teams_total_points_mean = np.mean(random_benchmark_teams_total_points_arr) \n",
    "random_benchmark_teams_total_points_std = np.std(random_benchmark_teams_total_points_arr)\n",
    "    \n",
    "random_benchmark_teams_total_points_mean, random_benchmark_teams_total_points_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:23:02.696358Z",
     "start_time": "2019-08-25T08:23:02.663429Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "    ('Linear regression', lr_total_points),\n",
    "    ('Ridge regression', ridge_total_points),\n",
    "    ('Lasso regression', lasso_total_points),\n",
    "    ('Principal component regression', pc_total_points),\n",
    "    ('Linear kernel', linear_total_points),\n",
    "    ('RBF kernel', rbf_total_points),\n",
    "    ('Decision tree', tree_total_points),\n",
    "    ('Random forest', forest_teams_total_points_mean),\n",
    "    ('Gradient boosted trees', boost_teams_total_points_mean),\n",
    "    ('Random team benchmark', random_benchmark_teams_total_points_mean),\n",
    "], columns=['model', 'teams total points']).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T09:19:09.978083Z",
     "start_time": "2019-08-25T09:19:09.969351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "points = [\n",
    "    1129,\n",
    "    1112,\n",
    "    1125,\n",
    "    1102,\n",
    "    1097,\n",
    "    1075,\n",
    "    1051,\n",
    "    1074,\n",
    "    1063,\n",
    "]\n",
    "\n",
    "errors = [\n",
    "    9.389,\n",
    "    9.411,\n",
    "    9.351,\n",
    "    9.382,\n",
    "    9.483,\n",
    "    9.444,\n",
    "    9.742,\n",
    "    9.412,\n",
    "    9.418,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T09:23:49.358194Z",
     "start_time": "2019-08-25T09:23:48.964154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(errors, points)\n",
    "plt.xlim(9.3, 9.8)\n",
    "plt.ylim(1040, 1140)\n",
    "plt.xlabel('Cross validation error (MSE)')\n",
    "plt.ylabel('Points')\n",
    "plt.grid()\n",
    "plt.title('Points against cross validation error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
